{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from clean_code.bitter_llm import LinearGater, RandomGater, discounted_rewards_torch\n",
    "from clean_code.off_policy_bitter_llm import OffPolicyBitterLLM\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "byte_layer_config: self.byte_layer_config._attn_implementation='eager'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OffPolicyBitterLLM(\n",
       "  (embedding): Embedding(256, 512)\n",
       "  (down_layers): ModuleList(\n",
       "    (0-1): 2 x OptimizedModule(\n",
       "      (_orig_mod): Gemma2DecoderLayer(\n",
       "        (self_attn): Gemma2Attention(\n",
       "          (q_proj): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (k_proj): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (v_proj): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (o_proj): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (rotary_emb): Gemma2RotaryEmbedding()\n",
       "        )\n",
       "        (mlp): Gemma2MLP(\n",
       "          (gate_proj): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (up_proj): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (down_proj): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (act_fn): PytorchGELUTanh()\n",
       "        )\n",
       "        (input_layernorm): Gemma2RMSNorm((512,), eps=1e-06)\n",
       "        (pre_feedforward_layernorm): Gemma2RMSNorm((512,), eps=1e-06)\n",
       "        (post_feedforward_layernorm): Gemma2RMSNorm((512,), eps=1e-06)\n",
       "        (post_attention_layernorm): Gemma2RMSNorm((512,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (mid_layers): ModuleList(\n",
       "    (0-5): 6 x OptimizedModule(\n",
       "      (_orig_mod): Gemma2DecoderLayer(\n",
       "        (self_attn): Gemma2Attention(\n",
       "          (q_proj): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (k_proj): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (v_proj): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (o_proj): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (rotary_emb): Gemma2RotaryEmbedding()\n",
       "        )\n",
       "        (mlp): Gemma2MLP(\n",
       "          (gate_proj): Linear(in_features=512, out_features=2048, bias=False)\n",
       "          (up_proj): Linear(in_features=512, out_features=2048, bias=False)\n",
       "          (down_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "          (act_fn): PytorchGELUTanh()\n",
       "        )\n",
       "        (input_layernorm): Gemma2RMSNorm((512,), eps=1e-06)\n",
       "        (pre_feedforward_layernorm): Gemma2RMSNorm((512,), eps=1e-06)\n",
       "        (post_feedforward_layernorm): Gemma2RMSNorm((512,), eps=1e-06)\n",
       "        (post_attention_layernorm): Gemma2RMSNorm((512,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up_layers): ModuleList(\n",
       "    (0-1): 2 x OptimizedModule(\n",
       "      (_orig_mod): Gemma2DecoderLayer(\n",
       "        (self_attn): Gemma2Attention(\n",
       "          (q_proj): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (k_proj): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (v_proj): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (o_proj): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (rotary_emb): Gemma2RotaryEmbedding()\n",
       "        )\n",
       "        (mlp): Gemma2MLP(\n",
       "          (gate_proj): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (up_proj): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (down_proj): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (act_fn): PytorchGELUTanh()\n",
       "        )\n",
       "        (input_layernorm): Gemma2RMSNorm((512,), eps=1e-06)\n",
       "        (pre_feedforward_layernorm): Gemma2RMSNorm((512,), eps=1e-06)\n",
       "        (post_feedforward_layernorm): Gemma2RMSNorm((512,), eps=1e-06)\n",
       "        (post_attention_layernorm): Gemma2RMSNorm((512,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (output_layer): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (down_layer_gate): LinearGater(\n",
       "    (linear): Linear(in_features=512, out_features=1, bias=True)\n",
       "  )\n",
       "  (downsampler): AverageTokenDownsampler()\n",
       "  (off_policy_gater): RandomGater()\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model = OffPolicyBitterLLM(\n",
    "    vocab_size=256, \n",
    "    embedding_dim=512, \n",
    "    num_heads=8, \n",
    "    downsample_rate=0.25, \n",
    "    sliding_window=64,\n",
    "    GaterClass=LinearGater,\n",
    "    OffPolicyGaterClass=RandomGater,\n",
    "    use_off_policy=True\n",
    ")\n",
    "\n",
    "my_model.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[243, 160,  63,  17,   1,  33, 217, 131, 201, 226],\n",
       "        [154, 200,  76, 167,  62,  83,  18, 235, 191,  68]], device='cuda:0')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_ids = torch.randint(0, 256, (2, 10)).cuda()\n",
    "token_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/itet-stor/sdauncey/net_scratch/conda_envs/geometric_diffusers/lib/python3.12/site-packages/torch/_inductor/compile_fx.py:150: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "out = my_model(token_ids)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 9.5384,  5.2708,  7.7629,  8.0215,  4.0989,  8.5190,  9.3597, 14.4296,\n",
       "         11.7884],\n",
       "        [12.0584,  7.4050, 10.3375,  6.0768, 12.9127, 10.7237,  9.1943, 12.6352,\n",
       "          9.7414]], device='cuda:0', grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = out[\"logits\"]\n",
    "down_gate_samples = out[\"down_gate_samples\"]\n",
    "off_policy_gate_probs = out[\"down_gate_probs\"]\n",
    "on_policy_probs = out[\"on_policy_probs\"]\n",
    "on_policy_logits = out[\"on_policy_logits\"]\n",
    "# Compute autoregressive loss: log probability of next token.\n",
    "next_token_ids = token_ids[:, 1:]\n",
    "current_token_logits = logits[:, :-1]\n",
    "next_token_logits = F.cross_entropy(current_token_logits.transpose(1, 2), next_token_ids, reduction=\"none\") # Transpose as F.cross_entropy wants shape [batch, classes, ...]\n",
    "ar_loss = next_token_logits.mean()\n",
    "\n",
    "next_token_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 9.5384,  5.2708,  7.7629,  8.0215,  4.0989,  8.5190,  9.3597, 14.4296,\n",
       "         11.7884,  0.0000],\n",
       "        [12.0584,  7.4050, 10.3375,  6.0768, 12.9127, 10.7237,  9.1943, 12.6352,\n",
       "          9.7414,  0.0000]], device='cuda:0', grad_fn=<CatBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_token_logits_padded = torch.cat([next_token_logits, torch.zeros(2, 1, device=next_token_logits.device)], dim=-1) # Pad the last reward as zero\n",
    "next_token_logits_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[15.9446, 12.8125, 15.0834, 14.6409, 13.2388, 18.2798, 19.5217, 20.3238,\n",
       "         11.7884,  0.0000],\n",
       "        [20.5275, 16.9381, 19.0663, 17.4575, 22.7614, 19.6973, 17.9473, 17.5059,\n",
       "          9.7414,  0.0000]], device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discounted_rewards = discounted_rewards_torch(next_token_logits_padded, 0.5)\n",
    "discounted_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.2914, -2.0628, -1.9914, -1.4083, -4.7613, -0.7088,  0.7872,  1.4089,\n",
       "          1.0235,  0.0000],\n",
       "        [ 2.2914,  2.0628,  1.9914,  1.4083,  4.7613,  0.7088, -0.7872, -1.4089,\n",
       "         -1.0235,  0.0000]], device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discounted_rewards = (discounted_rewards - discounted_rewards.mean(dim=0))\n",
    "discounted_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0000, 0.1557, 1.1165, 0.6073, 0.7121, 0.8154, 0.8295, 1.6167, 1.3842,\n",
       "         1.8384],\n",
       "        [-0.0000, 1.9978, 0.6139, 1.4178, 0.9176, 0.4970, 0.8359, 0.0949, 0.9186,\n",
       "         0.9255]], device='cuda:0', grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_log_probs = torch.stack([torch.zeros_like(on_policy_logits), on_policy_logits], dim=1) # As a sigmoid is equivalent to having one logit as 0.\n",
    "selected_action_log_probs = F.cross_entropy(action_log_probs, down_gate_samples, reduction=\"none\")\n",
    "selected_action_log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.1442, 0.6726, 0.4552, 0.5094, 0.4425, 0.5637, 0.8014, 0.7495,\n",
       "         0.1591],\n",
       "        [1.0000, 0.8644, 0.4588, 0.7578, 0.6005, 0.3916, 0.5665, 0.0905, 0.6009,\n",
       "         0.6037]], device='cuda:0', grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "on_policy_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.2500, 0.2500, 0.2500, 0.2500, 0.2500, 0.2500, 0.2500, 0.2500,\n",
       "         0.2500],\n",
       "        [1.0000, 0.2500, 0.2500, 0.2500, 0.2500, 0.2500, 0.2500, 0.2500, 0.2500,\n",
       "         0.2500]], device='cuda:0')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "off_policy_gate_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 0, 0, 0, 1, 0, 0, 0, 1],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "down_gate_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4.0000, 0.5768, 2.6903, 1.8207, 2.0375, 1.7698, 2.2549, 3.2058, 2.9979,\n",
       "         0.6363],\n",
       "        [4.0000, 3.4574, 1.8350, 3.0310, 2.4021, 1.5666, 2.2661, 0.3622, 2.4038,\n",
       "         2.4147]], device='cuda:0', grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "on_policy_probs / 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 1.1411, 0.4366, 0.7264, 0.6542, 0.7434, 0.5817, 0.2647, 0.3340,\n",
       "         1.1212],\n",
       "        [0.0000, 0.1809, 0.7217, 0.3230, 0.5326, 0.8111, 0.5780, 1.2126, 0.5321,\n",
       "         0.5284]], device='cuda:0', grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1 -  on_policy_probs) / 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[   nan, 1.0000],\n",
       "         [1.1411, 0.5768],\n",
       "         [0.4366, 2.6903],\n",
       "         [0.7264, 1.8207],\n",
       "         [0.6542, 2.0375],\n",
       "         [0.7434, 1.7698],\n",
       "         [0.5817, 2.2549],\n",
       "         [0.2647, 3.2058],\n",
       "         [0.3340, 2.9979],\n",
       "         [1.1212, 0.6363]],\n",
       "\n",
       "        [[   nan, 1.0000],\n",
       "         [0.1809, 3.4574],\n",
       "         [0.7217, 1.8350],\n",
       "         [0.3230, 3.0310],\n",
       "         [0.5326, 2.4021],\n",
       "         [0.8111, 1.5666],\n",
       "         [0.5780, 2.2661],\n",
       "         [1.2126, 0.3622],\n",
       "         [0.5321, 2.4038],\n",
       "         [0.5284, 2.4147]]], device='cuda:0')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# likelihood_ratios [:, :, 1] gives the likelihood ratio for the action of gating.\n",
    "likelihood_ratios = torch.stack([\n",
    "    (1 - on_policy_probs) / (1 - off_policy_gate_probs),\n",
    "    on_policy_probs / off_policy_gate_probs\n",
    "], dim=-1)\n",
    "likelihood_ratios = likelihood_ratios.detach() # Detach as we don't want to backpropagate through this.\n",
    "likelihood_ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 1.1411, 0.4366, 0.7264, 0.6542, 1.7698, 0.5817, 0.2647, 0.3340,\n",
       "         0.6363],\n",
       "        [1.0000, 0.1809, 0.7217, 0.3230, 0.5326, 0.8111, 0.5780, 1.2126, 0.5321,\n",
       "         0.5284]], device='cuda:0')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the likelihood ratios for the selected actions for importance sampling.\n",
    "selected_action_likelihood_ratios = likelihood_ratios.gather(dim=-1, index=down_gate_samples.unsqueeze(-1))\n",
    "selected_action_likelihood_ratios = selected_action_likelihood_ratios.squeeze(-1)\n",
    "selected_action_likelihood_ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(f\"{selected_action_likelihood_ratios.grad_fn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 10]), torch.Size([2, 10]))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_action_likelihood_ratios.shape, discounted_rewards.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000, -0.3665, -0.9707, -0.6213, -2.2179, -1.0228,  0.3798,  0.6030,\n",
       "          0.4732,  0.0000],\n",
       "        [-0.0000,  0.7453,  0.8822,  0.6449,  2.3271,  0.2857, -0.3803, -0.1621,\n",
       "         -0.5003,  0.0000]], device='cuda:0', dtype=torch.float64,\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_action_likelihood_ratios * discounted_rewards * selected_action_log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0000, 0.1557, 1.1165, 0.6073, 0.7121, 0.8154, 0.8295, 1.6167, 1.3842,\n",
       "         1.8384],\n",
       "        [-0.0000, 1.9978, 0.6139, 1.4178, 0.9176, 0.4970, 0.8359, 0.0949, 0.9186,\n",
       "         0.9255]], device='cuda:0', grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_action_log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
