{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.version import __version__\n",
    "import torch\n",
    "\n",
    "__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RoPE implementation borrowed from Gemma https://github.com/huggingface/transformers/blob/main/src/transformers/models/gemma/modeling_gemma.py\n",
    "# Just put some comments into it to inspect it.\n",
    "class GemmaRotaryEmbedding(nn.Module):\n",
    "    def __init__(self, dim, max_position_embeddings=2048, base=10000, device=None):\n",
    "        super().__init__()\n",
    "\n",
    "        self.dim = dim\n",
    "        self.max_position_embeddings = max_position_embeddings\n",
    "        self.base = base\n",
    "        inv_freq = 1.0 / (self.base ** (torch.arange(0, self.dim, 2, dtype=torch.int64).float() / self.dim))\n",
    "        self.register_buffer(\"inv_freq\", tensor=inv_freq, persistent=False)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def forward(self, x, position_ids, seq_len=None):\n",
    "        # position_ids: [bs, seq_len]\n",
    "        # x: [bs, num_attention_heads, seq_len, head_size]\n",
    "        # returns cos: [bs, seq_len, head_size] where cos[b, i, j] = cos(pos_ids[b, i] * inv_freq[j])\n",
    "        # returns sin: [bs, seq_len, head_size] where sin[b, i, j] = sin(pos_ids[b, i] * inv_freq[j])\n",
    "        self.inv_freq.to(x.device)\n",
    "        inv_freq_expanded = self.inv_freq[None, :, None].float().expand(position_ids.shape[0], -1, 1)\n",
    "        position_ids_expanded = position_ids[:, None, :].float()\n",
    "\n",
    "        print(position_ids_expanded.shape, inv_freq_expanded.shape)\n",
    "\n",
    "        # Force float32 since bfloat16 loses precision on long contexts\n",
    "        # See https://github.com/huggingface/transformers/pull/29285\n",
    "        device_type = x.device.type\n",
    "        device_type = device_type if isinstance(device_type, str) and device_type != \"mps\" else \"cpu\"\n",
    "\n",
    "        with torch.autocast(device_type=device_type, enabled=False):\n",
    "            freqs = (inv_freq_expanded.float() @ position_ids_expanded.float()).transpose(1, 2)\n",
    "            emb = torch.cat((freqs, freqs), dim=-1)\n",
    "            cos = emb.cos()\n",
    "            sin = emb.sin()\n",
    "\n",
    "        return cos.to(dtype=x.dtype), sin.to(dtype=x.dtype)\n",
    "\n",
    "def rotate_half(x):\n",
    "    \"\"\"Rotates half the hidden dims of the input.\"\"\"\n",
    "    x1 = x[..., : x.shape[-1] // 2]\n",
    "    x2 = x[..., x.shape[-1] // 2 :]\n",
    "    # if x[b, i] = ((1, 2, 3, 4, 5, 6..., a + 1, a+2, a+3..., 2a)) \n",
    "    # the rotate_half(x)[b, i] = ((-a-1, -a-2, -a-3..., -2a, 1, 2, 3, 4, 5, 6..., a))\n",
    "    return torch.cat((-x2, x1), dim=-1)\n",
    "\n",
    "\n",
    "def apply_rotary_pos_emb(q, k, cos, sin, position_ids=None, unsqueeze_dim=1):\n",
    "    \"\"\"Applies Rotary Position Embedding to the query and key tensors.\n",
    "\n",
    "    Args:\n",
    "        q (`torch.Tensor`): The query tensor.\n",
    "        k (`torch.Tensor`): The key tensor.\n",
    "        cos (`torch.Tensor`): The cosine part of the rotary embedding.\n",
    "        sin (`torch.Tensor`): The sine part of the rotary embedding.\n",
    "        position_ids (`torch.Tensor`, *optional*):\n",
    "            Deprecated and unused.\n",
    "        unsqueeze_dim (`int`, *optional*, defaults to 1):\n",
    "            The 'unsqueeze_dim' argument specifies the dimension along which to unsqueeze cos[position_ids] and\n",
    "            sin[position_ids] so that they can be properly broadcasted to the dimensions of q and k. For example, note\n",
    "            that cos[position_ids] and sin[position_ids] have the shape [batch_size, seq_len, head_dim]. Then, if q and\n",
    "            k have the shape [batch_size, heads, seq_len, head_dim], then setting unsqueeze_dim=1 makes\n",
    "            cos[position_ids] and sin[position_ids] broadcastable to the shapes of q and k. Similarly, if q and k have\n",
    "            the shape [batch_size, seq_len, heads, head_dim], then set unsqueeze_dim=2.\n",
    "    Returns:\n",
    "        `tuple(torch.Tensor)` comprising of the query and key tensors rotated using the Rotary Position Embedding.\n",
    "    \"\"\"\n",
    "    cos = cos.unsqueeze(unsqueeze_dim)\n",
    "    sin = sin.unsqueeze(unsqueeze_dim)\n",
    "    # The key is that (to translate the paper notation to code notation) \n",
    "    # x_j = x[..., (j+1)//2] if j is odd\n",
    "    # x_j = x[..., (head_dim + j)//2] if j is even\n",
    "    # and cos[b, i, j] = cos[b, i , j + head_dim//2]\n",
    "\n",
    "    # Such that, for j < head_dim // 2,\n",
    "    # q_embed[b, i, j] = q[b, i, j] * cos[b, i, j] - q[b, i, j + head_dim // 2] * sin[b, i, j]\n",
    "    # = x_j cos(theta_j) - x_{j+1} sin(theta_{j})\n",
    "\n",
    "    # and for j >= head_dim // 2,\n",
    "    # q_embed[b, i, j] = q[b, i, j] * cos[b, i, j] + q[b, i, j - head_dim // 2] * sin[b, i, j]\n",
    "    # = x_j cos(theta_j) + x_{j-1} sin(theta_{j-1})\n",
    "\n",
    "    q_embed = (q * cos) + (rotate_half(q) * sin)\n",
    "    k_embed = (k * cos) + (rotate_half(k) * sin)\n",
    "    return q_embed, k_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.models.gemma2.modeling_gemma2 import Gemma2DecoderLayer, Gemma2Config, Gemma2Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from typing import List\n",
    "\n",
    "from copy import deepcopy\n",
    "import torch\n",
    "\n",
    "from scipy.signal import lfilter\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import datasets\n",
    "\n",
    "def get_merge_dst(gate_samples: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Returns (merge_dst, dst_idx) the merge destination for each token in the sequence and the number of unique merge destinations.\n",
    "    For now, has a janky python for-loop implementation.\n",
    "    Input is a tensor of shape (batch_size, sequence_length) with 0 tokens are merged into the next 1 token.\n",
    "    \"\"\"\n",
    "    batch_size, seq_len = gate_samples.shape\n",
    "    merge_dst = torch.zeros_like(gate_samples, dtype=torch.long)\n",
    "    n_dst = torch.zeros(batch_size, dtype=torch.long)\n",
    "\n",
    "    # Process each batch separately\n",
    "    for b in range(batch_size):\n",
    "        dst_idx = 0\n",
    "        for i in range(seq_len):\n",
    "            merge_dst[b, i] = dst_idx\n",
    "            if gate_samples[b, i] == 1 and i < seq_len - 1:\n",
    "                # If previous position had gate=1, keep the same destination\n",
    "                dst_idx += 1\n",
    "\n",
    "        n_dst[b] = dst_idx + 1\n",
    "\n",
    "    return merge_dst, n_dst\n",
    "\n",
    "\n",
    "class GemmaMiniBitterLLM(nn.Module):\n",
    "    # A mini BitterLLM with 2 down, 4 mid, and 2 up layers. As a vibe check on the idea.\n",
    "    # Use Gemma2DecoderLayer as a drop in replacement for the TransformerEncoderLayer, with RoPE and sliding window pre-implemented.\n",
    "    # Also uses \n",
    "    def __init__(self, vocab_size: int, embedding_dim: int, num_heads: int, dropout: float=0.01, downsample_rate: float = 0.25, sliding_window = 64):\n",
    "        super().__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        head_dim = embedding_dim // num_heads\n",
    "\n",
    "\n",
    "        byte_layer_config = Gemma2Config(\n",
    "            head_dim=head_dim,\n",
    "            query_pre_attn_scalar=head_dim, \n",
    "            sliding_window=sliding_window,\n",
    "            intermediate_size=embedding_dim,\n",
    "            hidden_size=embedding_dim,\n",
    "            num_attention_heads=num_heads,\n",
    "            num_key_value_heads=num_heads,\n",
    "        )\n",
    "\n",
    "        deep_layer_config = Gemma2Config(\n",
    "            head_dim=head_dim,\n",
    "            query_pre_attn_scalar=head_dim, \n",
    "            sliding_window=None,\n",
    "            intermediate_size=embedding_dim * 4, # dim_feedforward should scale inversely with the number of tokens in the sequence.\n",
    "            hidden_size=embedding_dim,\n",
    "            num_attention_heads=num_heads,\n",
    "            num_key_value_heads=num_heads\n",
    "        )\n",
    "\n",
    "        \n",
    "        # Layer idx=0 is necessary for the sliding window to be applied.\n",
    "        self.down_layers = nn.ModuleList([\n",
    "            Gemma2DecoderLayer(byte_layer_config, layer_idx=0) for _ in range(2)\n",
    "        ])\n",
    "\n",
    "        self.mid_layers = nn.ModuleList([\n",
    "            Gemma2DecoderLayer(deep_layer_config, layer_idx=1) for _ in range(2) \n",
    "        ])\n",
    "\n",
    "        self.up_layers = nn.ModuleList([\n",
    "            Gemma2DecoderLayer(byte_layer_config, layer_idx=0) for _ in range(2)\n",
    "        ])\n",
    "\n",
    "        self.output_layer = nn.Linear(embedding_dim, vocab_size)\n",
    "        # Initialize a gate for each layer.\n",
    "        layer_gate_init = nn.Linear(embedding_dim, 1)\n",
    "\n",
    "        # Copy the gate for each layer. \n",
    "        # Initializing by copying inductively biases the model to tokenize in a later layer if the gate is high but the model chose not to.\n",
    "        self.down_layer_gate = deepcopy(layer_gate_init)\n",
    "        self.downsample_rate = downsample_rate\n",
    "\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "\n",
    "        batch_size, max_seq_len = x.shape\n",
    "\n",
    "\n",
    "        x = self.embedding(x)\n",
    "\n",
    "        position_ids = torch.arange(max_seq_len, dtype=x.dtype).unsqueeze(0).expand(batch_size, -1).to(x.device)\n",
    "\n",
    "        # Apply down layers to byte tokens        \n",
    "        for layer in self.down_layers:\n",
    "            x = layer(x, position_ids=position_ids)[0]\n",
    "\n",
    "        # Sample gating binary variables for each token.\n",
    "        down_gate_logits = self.down_layer_gate(x)\n",
    "        down_gate_probs = F.sigmoid(down_gate_logits)\n",
    "        down_gate_samples = torch.bernoulli(down_gate_probs)\n",
    "\n",
    "        # Hack: ensure for now that we always gate on the first token:\n",
    "        down_gate_samples[:, 0] = 1.\n",
    "\n",
    "        # Merge the tokens into the next token where the gate is 1.\n",
    "        down_gate_samples = down_gate_samples.squeeze(-1)\n",
    "        down_merge_dst, n_dst = get_merge_dst(down_gate_samples)\n",
    "\n",
    "        # Also merge the position ids.\n",
    "        position_ids_downsampled = torch.zeros(batch_size, n_dst.max(), dtype=x.dtype).to(x.device)\n",
    "        position_ids_downsampled = torch.scatter_reduce(position_ids_downsampled, dim=1, index=down_merge_dst, src=position_ids, reduce=\"mean\", include_self=False)\n",
    "\n",
    "        # Merge the downsampled tokens.\n",
    "        down_merge_dst = down_merge_dst.unsqueeze(-1).expand(-1, -1, self.embedding_dim)\n",
    "\n",
    "        x_downsampled = torch.zeros(batch_size, n_dst.max(), self.embedding_dim, dtype=x.dtype).to(x.device)\n",
    "        x_downsampled = torch.scatter_reduce(x_downsampled, dim=1, index=down_merge_dst, src=x, reduce=\"mean\", include_self=False)\n",
    "\n",
    "        # Apply mid layers to merged tokens and compute the deviation\n",
    "        for layer in self.mid_layers:\n",
    "            y_downsampled = layer(x_downsampled, position_ids=position_ids_downsampled)[0]\n",
    "            deviation = y_downsampled - x_downsampled        \n",
    "\n",
    "        # Upsample by removing the first token merge group, shifting all token groups down and adding another one token group at the end.\n",
    "        up_gate_samples = down_gate_samples[:, 1:]\n",
    "        up_gate_samples = torch.cat([up_gate_samples, torch.ones(batch_size, 1, dtype=up_gate_samples.dtype).to(up_gate_samples.device)], dim=1)\n",
    "        up_merge_dst, _ = get_merge_dst(up_gate_samples)\n",
    "        up_merge_dst = up_merge_dst.unsqueeze(-1).expand(-1, -1, self.embedding_dim)\n",
    "\n",
    "        # Add the upsampled deviation to the input to the middle layers\n",
    "        upsampled_deviation = torch.gather(deviation, dim=1, index=up_merge_dst)\n",
    "        y = x + upsampled_deviation\n",
    "\n",
    "        # Apply up layers to byte tokens\n",
    "        for layer in self.up_layers:\n",
    "            y = layer(y, position_ids=position_ids)[0]\n",
    "\n",
    "        # Map residual stream to logits\n",
    "        logits = self.output_layer(y)\n",
    "        logits = F.log_softmax(logits, dim=-1)\n",
    "\n",
    "        out = {\n",
    "            \"logits\": logits,\n",
    "            \"down_gate_probs\": down_gate_probs.squeeze(-1),\n",
    "            \"down_gate_logits\": down_gate_logits.squeeze(-1),\n",
    "            \"down_gate_samples\": down_gate_samples.to(dtype=torch.long),\n",
    "            \"down_merge_dst\": down_merge_dst[:, :, 0], # This dimension is repeated.\n",
    "            \"up_merge_dst\": up_merge_dst[:, :, 0],\n",
    "            \"n_dst\": n_dst,\n",
    "        }\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GemmaMiniBitterLLM(\n",
       "  (embedding): Embedding(5, 128)\n",
       "  (down_layers): ModuleList(\n",
       "    (0-1): 2 x Gemma2DecoderLayer(\n",
       "      (self_attn): Gemma2Attention(\n",
       "        (q_proj): Linear(in_features=128, out_features=128, bias=False)\n",
       "        (k_proj): Linear(in_features=128, out_features=128, bias=False)\n",
       "        (v_proj): Linear(in_features=128, out_features=128, bias=False)\n",
       "        (o_proj): Linear(in_features=128, out_features=128, bias=False)\n",
       "        (rotary_emb): Gemma2RotaryEmbedding()\n",
       "      )\n",
       "      (mlp): Gemma2MLP(\n",
       "        (gate_proj): Linear(in_features=128, out_features=128, bias=False)\n",
       "        (up_proj): Linear(in_features=128, out_features=128, bias=False)\n",
       "        (down_proj): Linear(in_features=128, out_features=128, bias=False)\n",
       "        (act_fn): PytorchGELUTanh()\n",
       "      )\n",
       "      (input_layernorm): Gemma2RMSNorm((128,), eps=1e-06)\n",
       "      (pre_feedforward_layernorm): Gemma2RMSNorm((128,), eps=1e-06)\n",
       "      (post_feedforward_layernorm): Gemma2RMSNorm((128,), eps=1e-06)\n",
       "      (post_attention_layernorm): Gemma2RMSNorm((128,), eps=1e-06)\n",
       "    )\n",
       "  )\n",
       "  (mid_layers): ModuleList(\n",
       "    (0-1): 2 x Gemma2DecoderLayer(\n",
       "      (self_attn): Gemma2Attention(\n",
       "        (q_proj): Linear(in_features=128, out_features=128, bias=False)\n",
       "        (k_proj): Linear(in_features=128, out_features=128, bias=False)\n",
       "        (v_proj): Linear(in_features=128, out_features=128, bias=False)\n",
       "        (o_proj): Linear(in_features=128, out_features=128, bias=False)\n",
       "        (rotary_emb): Gemma2RotaryEmbedding()\n",
       "      )\n",
       "      (mlp): Gemma2MLP(\n",
       "        (gate_proj): Linear(in_features=128, out_features=512, bias=False)\n",
       "        (up_proj): Linear(in_features=128, out_features=512, bias=False)\n",
       "        (down_proj): Linear(in_features=512, out_features=128, bias=False)\n",
       "        (act_fn): PytorchGELUTanh()\n",
       "      )\n",
       "      (input_layernorm): Gemma2RMSNorm((128,), eps=1e-06)\n",
       "      (pre_feedforward_layernorm): Gemma2RMSNorm((128,), eps=1e-06)\n",
       "      (post_feedforward_layernorm): Gemma2RMSNorm((128,), eps=1e-06)\n",
       "      (post_attention_layernorm): Gemma2RMSNorm((128,), eps=1e-06)\n",
       "    )\n",
       "  )\n",
       "  (up_layers): ModuleList(\n",
       "    (0-1): 2 x Gemma2DecoderLayer(\n",
       "      (self_attn): Gemma2Attention(\n",
       "        (q_proj): Linear(in_features=128, out_features=128, bias=False)\n",
       "        (k_proj): Linear(in_features=128, out_features=128, bias=False)\n",
       "        (v_proj): Linear(in_features=128, out_features=128, bias=False)\n",
       "        (o_proj): Linear(in_features=128, out_features=128, bias=False)\n",
       "        (rotary_emb): Gemma2RotaryEmbedding()\n",
       "      )\n",
       "      (mlp): Gemma2MLP(\n",
       "        (gate_proj): Linear(in_features=128, out_features=128, bias=False)\n",
       "        (up_proj): Linear(in_features=128, out_features=128, bias=False)\n",
       "        (down_proj): Linear(in_features=128, out_features=128, bias=False)\n",
       "        (act_fn): PytorchGELUTanh()\n",
       "      )\n",
       "      (input_layernorm): Gemma2RMSNorm((128,), eps=1e-06)\n",
       "      (pre_feedforward_layernorm): Gemma2RMSNorm((128,), eps=1e-06)\n",
       "      (post_feedforward_layernorm): Gemma2RMSNorm((128,), eps=1e-06)\n",
       "      (post_attention_layernorm): Gemma2RMSNorm((128,), eps=1e-06)\n",
       "    )\n",
       "  )\n",
       "  (output_layer): Linear(in_features=128, out_features=5, bias=True)\n",
       "  (down_layer_gate): Linear(in_features=128, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model = GemmaMiniBitterLLM(vocab_size=5, embedding_dim=128, num_heads=8, dropout=0.01, downsample_rate=0.25, sliding_window=64)\n",
    "my_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'logits': tensor([[[-3.4997, -1.6342, -0.4634, -1.9606, -5.3536],\n",
       "          [-3.6049, -1.5426, -0.4805, -1.9941, -5.4257],\n",
       "          [-0.8375, -0.9508, -1.9090, -3.5295, -5.7440],\n",
       "          [-3.6600, -2.7093, -0.1224, -4.8673, -4.1850],\n",
       "          [-1.1130, -0.6340, -1.9766, -7.1777, -6.4087],\n",
       "          [-4.3619, -3.3550, -0.0650, -4.6044, -5.2462],\n",
       "          [-3.5489, -1.5200, -0.5002, -1.9578, -5.3101],\n",
       "          [-3.5952, -1.4244, -0.5281, -1.9854, -5.3275],\n",
       "          [-3.7640, -3.1122, -0.0843, -4.8573, -5.2315],\n",
       "          [-1.7456, -0.5517, -1.4443, -5.4665, -4.6755]]],\n",
       "        grad_fn=<LogSoftmaxBackward0>),\n",
       " 'down_gate_probs': tensor([[0.7067, 0.7083, 0.5357, 0.6453, 0.5482, 0.6511, 0.7138, 0.7026, 0.6546,\n",
       "          0.4189]], grad_fn=<SqueezeBackward1>),\n",
       " 'down_gate_logits': tensor([[ 0.8794,  0.8869,  0.1431,  0.5985,  0.1933,  0.6237,  0.9138,  0.8598,\n",
       "           0.6395, -0.3274]], grad_fn=<SqueezeBackward1>),\n",
       " 'down_gate_samples': tensor([[1, 1, 0, 1, 1, 1, 1, 1, 0, 1]]),\n",
       " 'down_merge_dst': tensor([[0, 1, 2, 2, 3, 4, 5, 6, 7, 7]]),\n",
       " 'up_merge_dst': tensor([[0, 1, 1, 2, 3, 4, 5, 6, 6, 7]]),\n",
       " 'n_dst': tensor([8])}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x = torch.randint(0, 5, (1, 10))\n",
    "my_model(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BBAABABAABBAABBBAABABAA', 'ABAAABAABBAABABAA']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upper_patterns = [\"10110\", \"0010\"]\n",
    "lower_patterns = [\"ABAA\", \"BBAAB\"]\n",
    "\n",
    "imputed_upper_patterns = [\n",
    "    p.replace(\"0\", lower_patterns[0]).replace(\"1\", lower_patterns[1]) for p in upper_patterns\n",
    "]\n",
    "imputed_upper_patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(n_upper):\n",
    "    choices = [random.randint(0, 1) for _ in range(n_upper)]\n",
    "\n",
    "    x = \"\".join(\n",
    "        imputed_upper_patterns[c] for c in choices\n",
    "    )\n",
    "    return x, choices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('BBAABABAABBAABBBAABABAAABAAABAABBAABABAAABAAABAABBAABABAAABAAABAABBAABABAAABAAABAABBAABABAAABAAABAABBAABABAABBAABABAABBAABBBAABABAABBAABABAABBAABBBAABABAABBAABABAABBAABBBAABABAAABAAABAABBAABABAA',\n",
       " [0, 1, 1, 1, 1, 1, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Idea: force MiniBitterLM to learn these strings, with a context windom of 4 for the initial tokens.\n",
    "# In theory, there should be less than 2 / (6 + 4) * (4 + 6) = 1/50 bits per character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dataset = [sample(10) for _ in range(1000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def compute_discounted_rewards(rewards, discount):\n",
    "    \"\"\"\n",
    "    Assumes that rewards is a numpy array of shape (n_episodes, n_timesteps). Returns tensor of same shape.\n",
    "    credit to: https://stackoverflow.com/questions/47970683/vectorize-a-numpy-discount-calculation/47971187#47971187,\n",
    "    minor modifications made to vectorise computation.\n",
    "    C[i] = R[i] + discount * C[i+1]\n",
    "    signal.lfilter(b, a, x, axis=-1, zi=None)\n",
    "    a[0]*y[n] = b[0]*x[n] + b[1]*x[n-1] + ... + b[M]*x[n-M]\n",
    "                          - a[1]*y[n-1] - ... - a[N]*y[n-N]\n",
    "    \"\"\"\n",
    "    r = rewards[:, ::-1]\n",
    "    a = [1, -discount]\n",
    "    b = [1]\n",
    "    y = lfilter(b, a, x=r)\n",
    "    return y[:, ::-1]\n",
    "\n",
    "\n",
    "def discounted_rewards_torch(rewards, discount):\n",
    "    \"\"\"torch wrapper for compute_discounted_rewards. Warning: does _not_ allow for backprop through the rewards, which is fine for policy gradients.\"\"\"\n",
    "    rewards_device = rewards.device\n",
    "    rewards = rewards.detach().cpu().numpy()\n",
    "    discounted_rewards = compute_discounted_rewards(rewards, discount)\n",
    "    discounted_rewards = torch.tensor(discounted_rewards.copy(), device=rewards_device) # Copy as torch doesn't like converting negatively strided arrays\n",
    "    return discounted_rewards\n",
    "\n",
    "\n",
    "def bitter_tokenizer_training_step(model, batch, optimizer):\n",
    "    \"\"\"\n",
    "    Assume that batch is torch.tensor of token ids of shape (batch, sequence_length). returns a dict of floats of the training losses for the batch.\n",
    "    \"\"\"\n",
    "    batch_size, _ = batch.shape\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    out = model(batch)\n",
    "    logits = out[\"logits\"]\n",
    "    down_gate_samples = out[\"down_gate_samples\"]\n",
    "    down_gate_probs = out[\"down_gate_probs\"]\n",
    "    down_gate_logits = out[\"down_gate_logits\"]\n",
    "    \n",
    "    # Compute autoregressive loss: log probability of next token.\n",
    "    next_token_ids = batch[:, 1:]\n",
    "    current_token_logits = logits[:, :-1]\n",
    "    next_token_logits = F.cross_entropy(current_token_logits.transpose(1, 2), next_token_ids, reduction=\"none\") # Transpose as F.cross_entropy wants shape [batch, classes, ...]\n",
    "    ar_loss = next_token_logits.mean()\n",
    "\n",
    "    # Compute gating loss: discounted log probabilities of following token(s).\n",
    "    discount_rate = 0.99\n",
    "    next_token_logits_padded = torch.cat([next_token_logits, torch.zeros(batch_size, 1, device=next_token_logits.device)], dim=-1) # Pad the last reward as zero\n",
    "    discounted_rewards = discounted_rewards_torch(next_token_logits_padded, discount_rate)\n",
    "    discounted_rewards = (discounted_rewards - discounted_rewards.mean()) # Simple estimate of the advantage\n",
    "    return discounted_rewards\n",
    "\n",
    "    # action 0 = continue, action 1 = gate\n",
    "    action_log_probs = torch.stack([torch.zeros_like(down_gate_logits), down_gate_logits], dim=1) # As a sigmoid is equivalent to having one logit as 0.\n",
    "    selected_action_log_probs = F.cross_entropy(action_log_probs, down_gate_samples, reduction=\"none\")\n",
    "    gating_loss = - (discounted_rewards * selected_action_log_probs).mean() # Negative as we want to maximise the reward.\n",
    "\n",
    "    # Hacky additional consistency loss: make the downsampling rate match the training gating.\n",
    "    down_gate_rate_loss =  5.*(model.downsample_rate - down_gate_probs.mean()) **2\n",
    "\n",
    "    # Optimizer step\n",
    "    total_loss = ar_loss + gating_loss + down_gate_rate_loss\n",
    "\n",
    "    total_loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "    optimizer.step()\n",
    "    \n",
    "\n",
    "    out = {\n",
    "        \"ar_loss\": ar_loss.item(),\n",
    "        \"gating_loss\": gating_loss.item(),\n",
    "        \"rate_consistency_loss\": down_gate_rate_loss.item(),\n",
    "        \"total_loss\": total_loss.item(),\n",
    "        \"selected_action_ce\": selected_action_log_probs.mean().item()\n",
    "    }\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_batch = torch.randint(0, 5, (10, 500)).to(device)\n",
    "my_model = my_model.to(device)\n",
    "dummy_optim = torch.optim.Adam(my_model.parameters(), lr=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = bitter_tokenizer_training_step(my_model, my_batch, dummy_optim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f01eb448e60>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ce = out\n",
    "\n",
    "plt.plot(out[:].to(\"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def display_gating(tokens_ids, merge_dst):\n",
    "    \"\"\"Display how a SmallBitterLLM merges a sequence. token_ids and merge_dst are tensors of shape (sequence_length,).\"\"\"\n",
    "    previous_merge_dst = 0\n",
    "    for t_id, merge_destinantion in zip(tokens_ids, merge_dst):\n",
    "        merge_destinantion = merge_destinantion.item()\n",
    "        \n",
    "        t_txt = byte5_tokenizer.decode(t_id)\n",
    "        print(f\"{t_txt.replace('\\n', '\\\\n')}\", end=\"\")\n",
    "\n",
    "        if merge_destinantion != previous_merge_dst:\n",
    "            print(f\"|\", end=\"\")\n",
    "            previous_merge_dst = merge_destinantion\n",
    "\n",
    "    print()\n",
    "        \n",
    "\n",
    "\n",
    "def bitter_tokenizer_training_loop(model, train_dataset):\n",
    "    # TODO: validation dataset\n",
    "    # Create data loaders\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=128,\n",
    "        shuffle=True,\n",
    "        num_workers=4,\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    # See how the model merges a sequence.\n",
    "    test_string = openwebtext_8k[-1][\"text\"][:200]\n",
    "    print(f\"{test_string.replace('\\n', '\\\\n')}\")\n",
    "    test_batch = byte5_tokenizer.encode(test_string, return_tensors=\"pt\", padding=True).to(device)\n",
    "\n",
    "    # Initialize model and optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
    "    \n",
    "    # Start memory tracking\n",
    "    tracemalloc.start()\n",
    "    \n",
    "    # Training loop\n",
    "    num_epochs = 2\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        model = model.to(device)\n",
    "        train_losses = []\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, GPU usage:\")\n",
    "        display_gpu_memory()\n",
    "        \n",
    "        # CPU memory tracking\n",
    "        process = psutil.Process()\n",
    "        print(f\"CPU Memory before epoch: {process.memory_info().rss / (1024 * 1024):.2f} MB\")\n",
    "\n",
    "        batch_count = 0\n",
    "        for batch in train_loader:\n",
    "\n",
    "            batch = batch[\"text\"]\n",
    "            batch = byte5_tokenizer(batch, return_tensors=\"pt\", padding=True)[\"input_ids\"]\n",
    "            batch = batch[:, :4096]  # Truncate to maximum length of 4096 to save GPU memory.\n",
    "            batch = batch.to(device)\n",
    "\n",
    "            loss_dict = bitter_tokenizer_training_step(model, batch, optimizer)\n",
    "            train_losses.append(loss_dict)\n",
    "\n",
    "            # Memory tracking for each batch\n",
    "            if batch_count % 10 == 0:\n",
    "                # print(f\"CPU Memory at batch {batch_count}: {process.memory_info().rss / (1024 * 1024):.2f} MB\")\n",
    "                # current, peak = tracemalloc.get_traced_memory()\n",
    "                # print(f\"Current memory usage: {current / 10**6:.2f} MB; Peak: {peak / 10**6:.2f} MB\")\n",
    "                \n",
    "                # # Force garbage collection to see if memory is being properly released\n",
    "                # gc.collect()\n",
    "                # print(f\"After GC: {process.memory_info().rss / (1024 * 1024):.2f} MB\")\n",
    "                print(f\"Batch {batch_count} ar train loss: {loss_dict['ar_loss']} nats/token\")\n",
    "                with torch.no_grad():\n",
    "                    out = model(test_batch)\n",
    "                display_gating(test_batch[0], out[\"down_merge_dst\"][0])\n",
    "\n",
    "            batch_count += 1\n",
    "\n",
    "        # Print metrics\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        print(f\"Train loss: {np.mean([l['total_loss'] for l in train_losses]):.4f}\")\n",
    "        \n",
    "        # Memory snapshot at end of epoch\n",
    "        print(f\"CPU Memory after epoch: {process.memory_info().rss / (1024 * 1024):.2f} MB\")\n",
    "        snapshot = tracemalloc.take_snapshot()\n",
    "        top_stats = snapshot.statistics('lineno')\n",
    "        print(\"[ Top 10 memory consumers ]\")\n",
    "        for stat in top_stats[:10]:\n",
    "            print(stat)\n",
    "    \n",
    "    # Stop memory tracking\n",
    "    tracemalloc.stop()\n",
    "    \n",
    "    train_losses = pd.DataFrame(train_losses)\n",
    "\n",
    "    return train_losses"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
